name: Telegram Latest News (Web Scraping)

on:
  schedule:
    - cron: "*/15 * * * *"  # UTC
  workflow_dispatch:

jobs:
  send:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Install dependencies
        run: pip install requests beautifulsoup4

      - name: Run Scraper Script
        env:
          BOT_TOKEN: ${{ secrets.TG_BOT_TOKEN }}
          CHAT_ID: "@netralnews_2026"
        run: |
          python3 - << 'EOF'
          import os
          import requests
          from bs4 import BeautifulSoup
          from datetime import datetime

          BOT_TOKEN = os.environ["BOT_TOKEN"]
          CHAT_ID = os.environ["CHAT_ID"]

          print("=== Scraper Job Started UTC:", datetime.utcnow(), "===")

          # Sumber situs
          SITES = {
              "KOMPAS": "https://www.kompas.com/",
              "BISNIS": "https://www.bisnis.com/",
              "CNN INDONESIA": "https://www.cnnindonesia.com/",
              "GOAL (BOLA)": "https://www.goal.com/id/news"
          }

          # Load history link yang sudah dikirim
          sent_links = set()
          if os.path.exists("last.txt"):
              with open("last.txt","r") as f:
                  sent_links = set(line.strip() for line in f.readlines() if line.strip())

          new_links = []
          messages = []

          for source, url in SITES.items():
              try:
                  r = requests.get(url, timeout=12, headers={"User-Agent": "Mozilla/5.0"})
                  if r.status_code != 200:
                      print(f"[WARN] {source} gagal diakses ({r.status_code})")
                      continue
                  soup = BeautifulSoup(r.content, "html.parser")
              except Exception as e:
                  print(f"[ERROR] {source} exception: {e}")
                  continue

              # Parsing per site (contoh untuk list berita utama)
              if source == "KOMPAS":
                  articles = soup.select("div.article__list article a")[:5]
              elif source == "BISNIS":
                  articles = soup.select("div.news-content a")[:5]
              elif source == "CNN INDONESIA":
                  articles = soup.select("article.post a")[:5]
              elif source == "GOAL (BOLA)":
                  articles = soup.select("div.feed-post a")[:5]
              else:
                  articles = []

              for a in articles:
                  title = a.get_text(strip=True)
                  link = a['href']
                  if not link.startswith("http"):
                      link = url.rstrip("/") + link
                  if link in sent_links:
                      continue
                  msg = f"ðŸ—žï¸ {source}\n{title}\n{link}"
                  messages.append(msg)
                  new_links.append(link)

          if not messages:
              print("[INFO] Tidak ada berita baru untuk dikirim")
              exit()

          # Kirim dari yang paling lama
          messages.reverse()
          new_links.reverse()

          for msg in messages:
              send_url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
              try:
                  resp = requests.post(send_url, data={"chat_id": CHAT_ID, "text": msg})
                  print(f"[POST] Status: {resp.status_code}, len: {len(msg)}")
              except Exception as e:
                  print(f"[ERROR] Telegram post failed: {e}")

          # Simpan history max 200 link
          history_limit = 200
          all_links = list(sent_links) + new_links
          with open("last.txt","w") as f:
              for l in all_links[-history_limit:]:
                  f.write(l + "\n")

          print("=== Scraper Job Finished UTC:", datetime.utcnow(), "===")
          EOF

      - name: Commit last.txt
        run: |
          git config user.name "rss-bot"
          git config user.email "bot@github.com"
          git add last.txt
          git commit -m "Update last scraped links" || echo "No new links"
          git push
